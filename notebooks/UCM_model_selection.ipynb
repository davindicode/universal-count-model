{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Head direction attractor network\n",
    "\n",
    "\n",
    "### Table of contents\n",
    "\n",
    "1. [**Synthetic population**](#synthetic)\n",
    "3. [**SNN**](#snn)\n",
    "4. [**RNN**](#rnn)\n",
    "\n",
    "This notebook contains analysis of different UCM hyperparameters and does model comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.13.0+cu117\n",
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.special as sps\n",
    "import scipy.stats as scstats\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../lib/\") # access to library\n",
    "sys.path.append(\"../scripts/\") # access to scripts\n",
    "\n",
    "import os\n",
    "if not os.path.exists('./saves'):\n",
    "    os.makedirs('./saves')\n",
    "    \n",
    "\n",
    "import neuroprob as nprb\n",
    "from neuroprob import utils\n",
    "\n",
    "\n",
    "device = nprb.inference.get_device(gpu=0)\n",
    "\n",
    "import models\n",
    "#import ucm_stats\n",
    "\n",
    "import pickle\n",
    "\n",
    "plt.style.use(['paper.mplstyle'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='loading'></a>\n",
    "## 1. Loading a trained model\n",
    "\n",
    "Here we specify the dataset used for training and the model architecture hyperparameters. This model is the UCM fit to observed covariates ```x_mode = 'hd-w-s-pos-t'```, meaning head direction (```hd```), angular head velocity (```w```), speed (```s```), animal $x$ and $y$ position (```pos```, two dimensions), and absolute time since the start of the recording session (```t```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/'\n",
    "data_type = 'th1'\n",
    "bin_size = 40\n",
    "\n",
    "dataset_dict = models.get_dataset(data_type, bin_size, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = '../scripts/checkpoint/'\n",
    "config_name = 'th1_U-el-4_svgp-64_X[hd-omega-speed-x-y-time]_Z[]_40K11_0d0_10f-1'\n",
    "batch_info = 500\n",
    "\n",
    "\n",
    "full_model, training_loss, fit_dict, val_dict = models.load_model(\n",
    "    config_name,\n",
    "    checkpoint_dir,\n",
    "    dataset_dict,\n",
    "    batch_info,\n",
    "    device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fed8805cfd0>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 245x183.75 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs = [1, 2, 3, 5, 6, 8]\n",
    "batch_info = 500\n",
    "\n",
    "config_names = [\n",
    "    'th1_U-el-2_svgp-64_X[hd-omega-speed-x-y-time]_Z[]_40K11_0d0_10f{}'.format(cv) \n",
    "    for cv in cvs\n",
    "] + [\n",
    "    'th1_U-el-3_svgp-64_X[hd-omega-speed-x-y-time]_Z[]_40K11_0d0_10f{}'.format(cv) \n",
    "    for cv in cvs\n",
    "] + [\n",
    "    'th1_U-el-4_svgp-64_X[hd-omega-speed-x-y-time]_Z[]_40K11_0d0_10f{}'.format(cv) \n",
    "    for cv in cvs\n",
    "] + [\n",
    "    'th1_U-eq-3_svgp-64_X[hd-omega-speed-x-y-time]_Z[]_40K11_0d0_10f{}'.format(cv) \n",
    "    for cv in cvs\n",
    "]\n",
    "\n",
    "\n",
    "Ell = []\n",
    "for name in config_names:\n",
    "    full_model, training_loss, fit_dict, val_dict = models.load_model(\n",
    "        name,\n",
    "        checkpoint_dir,\n",
    "        dataset_dict,\n",
    "        batch_info,\n",
    "        device,\n",
    "    )\n",
    "    \n",
    "    Ell.append(\n",
    "        models.RG_pred_ll(\n",
    "            full_model,\n",
    "            val_dict,\n",
    "            neuron_group=None,\n",
    "            ll_mode=\"GH\",\n",
    "            ll_samples=100,\n",
    "            cov_samples=1,\n",
    "            beta=0.0,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "Ell = np.array(Ell).reshape(-1, len(cvs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ErrorbarContainer object of 3 artists>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 245x183.75 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.errorbar(np.arange(Ell.shape[0]), Ell.mean(-1), yerr=Ell.std(-1) / np.sqrt(len(cvs)), capsize=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatype = 1\n",
    "rcov, neurons, tbin, resamples, rc_t = validation.get_dataset(datatype, '../scripts/data')\n",
    "max_count = int(rc_t.max())\n",
    "trials = 1\n",
    "\n",
    "use_neuron = np.arange(50)\n",
    "\n",
    "\n",
    "rhd_t = rcov[0]\n",
    "ra_t = rcov[1]\n",
    "covariates = [rhd_t[None, :, None].repeat(trials, axis=0), \n",
    "              ra_t[None, :, None].repeat(trials, axis=0)]\n",
    "glm = validation.IP_bumps(tbin, resamples, covariates, neurons, trials=trials)\n",
    "glm.to(dev)\n",
    "\n",
    "checkpoint = torch.load('../scripts/data/IP_HDC_model', map_location='cuda:0')\n",
    "glm.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = [('GP', 'IP', 'hd', 8, 'exp', 1, [], False, 10, False, 'ew'), \n",
    "         ('GP', 'U', 'hd', 8, 'identity', 3, [], False, 10, False, 'ew'),\n",
    "         ('GP', 'U', 'hdxR1', 16, 'identity', 3, [1], False, 10, False, 'ew')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# neuron subgroup likelihood CV\n",
    "beta = 0.0\n",
    "n_group = np.arange(5)\n",
    "val_neuron = [n_group, n_group+10, n_group+20, n_group+30, n_group+40]\n",
    "ncvx = 2\n",
    "kcvs = [2, 5, 8] # validation sets chosen in 10-fold split of data\n",
    "Ms = modes[:3]\n",
    "\n",
    "batch_size = 5000\n",
    "cv_pll = []\n",
    "for em, mode in enumerate(Ms):\n",
    "    for cvdata in model_utils.get_cv_sets(mode, kcvs, batch_size, rc_t, resamples, rcov):\n",
    "        _, ftrain, fcov, vtrain, vcov, cvbatch_size = cvdata\n",
    "        cv_set = (ftrain, fcov, vtrain, vcov)\n",
    "        \n",
    "        if em > 1:\n",
    "            for v_neuron in val_neuron:\n",
    "\n",
    "                prev_ll = np.inf\n",
    "                for tr in range(ncvx):\n",
    "                    full_model = get_full_model(datatype, cvdata, resamples, rc_t, 100, \n",
    "                                                mode, rcov, max_count, neurons)\n",
    "                    mask = np.ones((neurons,), dtype=bool)\n",
    "                    mask[v_neuron] = False\n",
    "                    f_neuron = np.arange(neurons)[mask]\n",
    "                    ll = model_utils.LVM_pred_ll(full_model, mode[-5], mode[2], models.cov_used, cv_set, f_neuron, v_neuron, \n",
    "                                                 beta=beta, beta_z=0.0, max_iters=3000)[0]\n",
    "                    if ll < prev_ll:\n",
    "                        prev_ll = ll\n",
    "\n",
    "                cv_pll.append(prev_ll)\n",
    "                \n",
    "        else:\n",
    "            for v_neuron in val_neuron:\n",
    "                full_model = get_full_model(datatype, cvdata, resamples, rc_t, 100, \n",
    "                                            mode, rcov, max_count, neurons)\n",
    "                cv_pll.append(model_utils.RG_pred_ll(full_model, mode[2], models.cov_used, cv_set, bound='ELBO', \n",
    "                                                     beta=beta, neuron_group=v_neuron, ll_mode='GH', ll_samples=100))\n",
    "\n",
    "        \n",
    "cv_pll = np.array(cv_pll).reshape(len(Ms), len(kcvs), len(val_neuron))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute tuning curves and latent trajectories for XZ joint regression-latent model\n",
    "mode = modes[2]\n",
    "cvdata = model_utils.get_cv_sets(mode, [-1], 5000, rc_t, resamples, rcov)[0]\n",
    "\n",
    "full_model = get_full_model(datatype, cvdata, resamples, rc_t, 100, \n",
    "                            mode, rcov, max_count, neurons)\n",
    "\n",
    "# latents\n",
    "X_loc, X_std = full_model.inputs.eval_XZ()\n",
    "\n",
    "T = X_loc[1].shape[0]\n",
    "X_c, shift, sign, scale, _ = utils.latent.signed_scaled_shift(X_loc[1], ra_t[:T], \n",
    "                                                              dev, 'euclid', learn_scale=True)\n",
    "X_s = scale*X_std[1]\n",
    "\n",
    "\n",
    "\n",
    "# tuning\n",
    "steps = 100\n",
    "covariates_z = [0.*np.ones(steps), np.linspace(X_loc[1].min(), X_loc[1].max(), steps)]\n",
    "P_mc = model_utils.compute_P(full_model, covariates_z, use_neuron, MC=1000).cpu()\n",
    "\n",
    "x_counts = torch.arange(max_count+1)\n",
    "avg = (x_counts[None, None, None, :]*P_mc).sum(-1)\n",
    "xcvar = ((x_counts[None, None, None, :]**2*P_mc).sum(-1)-avg**2)\n",
    "ff = xcvar/avg\n",
    "\n",
    "avgs = utils.signal.percentiles_from_samples(avg, percentiles=[0.05, 0.5, 0.95], \n",
    "                                             smooth_length=5, padding_mode='replicate')\n",
    "avglower, avgmean, avgupper = [cs_.cpu().numpy() for cs_ in avgs]\n",
    "\n",
    "ffs = utils.signal.percentiles_from_samples(ff, percentiles=[0.05, 0.5, 0.95], \n",
    "                                            smooth_length=5, padding_mode='replicate')\n",
    "fflower, ffmean, ffupper = [cs_.cpu().numpy() for cs_ in ffs]\n",
    "\n",
    "\n",
    "covariates_z[1] = sign*scale*covariates_z[1]+shift\n",
    "grate = glm.mapping.eval_rate(covariates_z, use_neuron)[0, ...]\n",
    "gFF = np.ones_like(grate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KS framework\n",
    "Qq = []\n",
    "Zz = []\n",
    "R = []\n",
    "Rp = []\n",
    "\n",
    "batch_size = 5000\n",
    "\n",
    "Ms = modes[:3]\n",
    "CV = [2, 5, 8]\n",
    "for kcv in CV:\n",
    "    for en, mode in enumerate(Ms):\n",
    "        cvdata = model_utils.get_cv_sets(mode, [kcv], batch_size, rc_t, resamples, rcov)[0]\n",
    "        _, ftrain, fcov, vtrain, vcov, cvbatch_size = cvdata\n",
    "        time_steps = ftrain.shape[-1]\n",
    "            \n",
    "        full_model = get_full_model(datatype, cvdata, resamples, rc_t, 100, \n",
    "                                    mode, rcov, max_count, neurons)\n",
    "\n",
    "        if en > 0:\n",
    "            # predictive posterior\n",
    "            q_ = []\n",
    "            Z_ = []\n",
    "            for b in range(full_model.inputs.batches):\n",
    "                P_mc = model_utils.compute_pred_P(full_model, b, use_neuron, None, cov_samples=10, ll_samples=1, tr=0)\n",
    "                P = P_mc.mean(0).cpu().numpy()\n",
    "\n",
    "                for n in range(len(use_neuron)):\n",
    "                    spike_binned = full_model.likelihood.spikes[b][0, n, :].numpy()\n",
    "                    q, Z = model_utils.get_q_Z(P[n, ...], spike_binned, deq_noise=None)\n",
    "\n",
    "                    if b == 0:\n",
    "                        q_.append(q)\n",
    "                        Z_.append(Z)\n",
    "                    else:\n",
    "                        q_[n] = np.concatenate((q_[n], q))\n",
    "                        Z_[n] = np.concatenate((Z_[n], Z))\n",
    "\n",
    "        elif en == 0:\n",
    "            cov_used = models.cov_used(mode[2], fcov)\n",
    "            q_ = model_utils.compute_count_stats(full_model, 'IP', tbin, ftrain, cov_used, use_neuron, \\\n",
    "                                                 traj_len=1, start=0, T=time_steps, bs=5000)\n",
    "            Z_ = [utils.stats.q_to_Z(q) for q in q_]\n",
    "\n",
    "\n",
    "        Pearson_s = []\n",
    "        for n in range(len(use_neuron)):\n",
    "            for m in range(n+1, len(use_neuron)):\n",
    "                r, r_p = scstats.pearsonr(Z_[n], Z_[m]) # Pearson r correlation test\n",
    "                Pearson_s.append((r, r_p))\n",
    "\n",
    "        r = np.array([p[0] for p in Pearson_s])\n",
    "        r_p = np.array([p[1] for p in Pearson_s])\n",
    "\n",
    "        Qq.append(q_)\n",
    "        Zz.append(Z_)\n",
    "        R.append(r)\n",
    "        Rp.append(r_p)\n",
    "\n",
    "    \n",
    "    \n",
    "fisher_z = []\n",
    "fisher_q = []\n",
    "for en, r in enumerate(R):\n",
    "    fz = 0.5*np.log((1+r)/(1-r))*np.sqrt(time_steps-3)\n",
    "    fisher_z.append(fz)\n",
    "    fisher_q.append(utils.stats.Z_to_q(fz))\n",
    "    \n",
    "    \n",
    "    \n",
    "q_DS_ = []\n",
    "T_DS_ = []\n",
    "T_KS_ = []\n",
    "for q in Qq:\n",
    "    for qq in q:\n",
    "        T_DS, T_KS, sign_DS, sign_KS, p_DS, p_KS = utils.stats.KS_statistics(qq, alpha=0.05, alpha_s=0.05)\n",
    "        T_DS_.append(T_DS)\n",
    "        T_KS_.append(T_KS)\n",
    "        \n",
    "        Z_DS = T_DS/np.sqrt(2/(qq.shape[0]-1))\n",
    "        q_DS_.append(utils.stats.Z_to_q(Z_DS))\n",
    "\n",
    "\n",
    "q_DS_ = np.array(q_DS_).reshape(len(CV), len(Ms), -1)\n",
    "T_DS_ = np.array(T_DS_).reshape(len(CV), len(Ms), -1)\n",
    "T_KS_ = np.array(T_KS_).reshape(len(CV), len(Ms), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise correlation structure\n",
    "NN = len(use_neuron)\n",
    "R_mat_Xp = np.zeros((NN, NN))\n",
    "R_mat_X = np.zeros((NN, NN))\n",
    "R_mat_XZ = np.zeros((NN, NN))\n",
    "for a in range(len(R[0])):\n",
    "    n, m = model_utils.ind_to_pair(a, NN)\n",
    "    R_mat_Xp[n, m] = R[0][a]\n",
    "    R_mat_X[n, m] = R[1][a]\n",
    "    R_mat_XZ[n, m] = R[2][a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_run = (\n",
    "    q_DS_, T_DS_, T_KS_, sign_DS, fisher_z, fisher_q, Qq, Zz, \n",
    "    R, Rp, X_c, X_s, ra_t, R_mat_Xp, R_mat_X, R_mat_XZ, cv_pll, \n",
    "    covariates_z, avglower, avgmean, avgupper, fflower, ffmean, ffupper, \n",
    "    grate, gFF, \n",
    "    use_neuron, max_count, tbin, rcov\n",
    ")\n",
    "\n",
    "pickle.dump(data_run, open('./saves/P2.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hCMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = [('GP', 'IP', 'hd', 8, 'exp', 1, [], False, 10, False, 'ew'), \n",
    "         ('GP', 'hNB', 'hd', 8, 'exp', 1, [], False, 10, False, 'ew'), \n",
    "         ('GP', 'U', 'hd', 8, 'identity', 3, [], False, 10, False, 'ew'), \n",
    "         ('ANN', 'U', 'hd', 8, 'identity', 3, [], False, 10, False, 'ew'), \n",
    "         ('GP', 'IP', 'T1', 8, 'exp', 1, [0], False, 10, False, 'ew'), \n",
    "         ('GP', 'hNB', 'T1', 8, 'exp', 1, [0], False, 10, False, 'ew'), \n",
    "         ('GP', 'U', 'T1', 8, 'identity', 3, [0], False, 10, False, 'ew'), \n",
    "         ('ANN', 'U', 'T1', 8, 'identity', 3, [0], False, 10, False, 'ew')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatype = 0\n",
    "rcov, neurons, tbin, resamples, rc_t = validation.get_dataset(datatype, '../scripts/data')\n",
    "max_count = int(rc_t.max())\n",
    "\n",
    "use_neuron = list(range(neurons))\n",
    "\n",
    "\n",
    "rhd_t = rcov[0]\n",
    "trials = 1\n",
    "covariates = [rhd_t[None, :, None].repeat(trials, axis=0)]\n",
    "glm = validation.CMP_hdc(tbin, resamples, covariates, neurons, trials=trials)\n",
    "glm.to(dev)\n",
    "\n",
    "checkpoint = torch.load('../scripts/data/hCMP_HDC_model', map_location='cpu')\n",
    "\n",
    "glm.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-validation of regression models\n",
    "beta = 0.0\n",
    "kcvs = [2, 5, 8] # validation sets chosen in 10-fold split of data\n",
    "batch_size = 5000\n",
    "\n",
    "Ms = modes[:4]\n",
    "RG_cv_ll = []\n",
    "for mode in Ms:\n",
    "    for cvdata in model_utils.get_cv_sets(mode, kcvs, batch_size, rc_t, resamples, rcov):\n",
    "        _, ftrain, fcov, vtrain, vcov, cvbatch_size = cvdata\n",
    "        cv_set = (ftrain, fcov, vtrain, vcov)\n",
    "        \n",
    "        full_model = get_full_model(datatype, cvdata, resamples, rc_t, 100, \n",
    "                                    mode, rcov, max_count, neurons)\n",
    "        RG_cv_ll.append(model_utils.RG_pred_ll(full_model, mode[2], models.cov_used, cv_set, bound='ELBO', \n",
    "                                               beta=beta, neuron_group=None, ll_mode='GH', ll_samples=100))\n",
    "    \n",
    "RG_cv_ll = np.array(RG_cv_ll).reshape(len(Ms), len(kcvs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute tuning curves of ground truth model\n",
    "batch_size = 5000\n",
    "\n",
    "cvdata = model_utils.get_cv_sets(mode, [2], batch_size, rc_t, resamples, rcov)[0]\n",
    "full_model = get_full_model(datatype, cvdata, resamples, rc_t, 100, \n",
    "                            modes[2], rcov, max_count, neurons)\n",
    "\n",
    "\n",
    "\n",
    "steps = 100\n",
    "covariates = [np.linspace(0, 2*np.pi, steps)]\n",
    "P_mc = model_utils.compute_P(full_model, covariates, use_neuron, MC=1000)\n",
    "P_rg = P_mc.mean(0).cpu().numpy()\n",
    "\n",
    "x_counts = torch.arange(max_count+1)\n",
    "\n",
    "\n",
    "\n",
    "mu = glm.mapping.eval_rate(covariates, use_neuron)[0:1, ...] # mu is the rate, so need to multiply by tbin\n",
    "log_nu = glm.likelihood.dispersion_mapping.eval_rate(covariates, use_neuron)[0:1, ...]\n",
    "\n",
    "log_mudt = torch.tensor(np.log(mu*tbin)).to(dev)\n",
    "nu = torch.tensor(np.exp(log_nu)).to(dev)\n",
    "\n",
    "AD = False # using Autograd for computing the CMP partition function is slow...\n",
    "if AD: # differentiate the partition function\n",
    "    t = torch.tensor(0.).to(dev)\n",
    "    t.requires_grad = True\n",
    "    log_Z = glm.likelihood.log_Z(log_mu+t, nu)\n",
    "\n",
    "    grad_t = torch.empty(log_Z.shape)\n",
    "    ggrad_t = torch.empty(log_Z.shape)\n",
    "    for n in use_neuron:\n",
    "        print(n)\n",
    "        for s in range(steps):\n",
    "            ind = torch.zeros_like(log_Z)\n",
    "            ind[0, n, s] = 1.\n",
    "            grad_t_, = torch.autograd.grad(log_Z, t, ind, retain_graph=True, create_graph=True)\n",
    "            grad_t[0, n, s] = grad_t_\n",
    "\n",
    "            ggrad_t_, = torch.autograd.grad(grad_t_, t, retain_graph=True, create_graph=True)\n",
    "            ggrad_t[0, n, s] = ggrad_t_\n",
    "\n",
    "\n",
    "    gmean = grad_t.data.cpu().numpy()[0, ...]\n",
    "    gvar = ggrad_t.data.cpu().numpy()[0, ...]\n",
    "\n",
    "else: # compute the partition function explicitly\n",
    "    gmean = utils.stats.cmp_moments(1, mu[0, ...], nu.cpu().numpy()[0, ...], tbin, J=10000)\n",
    "    gvar = utils.stats.cmp_moments(2, mu[0, ...], nu.cpu().numpy()[0, ...], tbin, J=10000) - gmean**2\n",
    "    \n",
    "grate = mu[0, ...]\n",
    "gdisp = nu.cpu().numpy()[0, ...]\n",
    "gFF = gvar/gmean\n",
    "\n",
    "\n",
    "\n",
    "# compute tuning curves and SCDs for model fit\n",
    "ref_prob = []\n",
    "hd = [20, 50, 80]\n",
    "for hd_ in hd:\n",
    "    for n in range(len(use_neuron)):\n",
    "        ref_prob.append([utils.stats.cmp_count_prob(xc, grate[n, hd_], gdisp[n, hd_], tbin) for xc in x_counts.numpy()])\n",
    "ref_prob = np.array(ref_prob).reshape(len(hd), len(use_neuron), -1)\n",
    "\n",
    "cs = utils.signal.percentiles_from_samples(P_mc[..., hd, :], percentiles=[0.05, 0.5, 0.95], smooth_length=1)\n",
    "clower, cmean, cupper = [cs_.cpu().numpy() for cs_ in cs]\n",
    "\n",
    "\n",
    "avg = (x_counts[None, None, None, :]*P_mc.cpu()).sum(-1)\n",
    "xcvar = ((x_counts[None, None, None, :]**2*P_mc.cpu()).sum(-1)-avg**2)\n",
    "ff = xcvar/avg\n",
    "\n",
    "avgs = utils.signal.percentiles_from_samples(avg, percentiles=[0.05, 0.5, 0.95], \n",
    "                                             smooth_length=5, padding_mode='circular')\n",
    "avglower, avgmean, avgupper = [cs_.cpu().numpy() for cs_ in avgs]\n",
    "\n",
    "ffs = utils.signal.percentiles_from_samples(ff, percentiles=[0.05, 0.5, 0.95], \n",
    "                                            smooth_length=5, padding_mode='circular')\n",
    "fflower, ffmean, ffupper = [cs_.cpu().numpy() for cs_ in ffs]\n",
    "\n",
    "xcvars = utils.signal.percentiles_from_samples(xcvar, percentiles=[0.05, 0.5, 0.95], \n",
    "                                               smooth_length=5, padding_mode='circular')\n",
    "varlower, varmean, varupper = [cs_.cpu().numpy() for cs_ in xcvars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# KS framework\n",
    "Qq_rg = []\n",
    "Zz_rg = []\n",
    "\n",
    "batch_size = 5000\n",
    "M = modes[:4]\n",
    "CV = [2, 5, 8]\n",
    "for kcv in CV:\n",
    "    for en, mode in enumerate(M):\n",
    "        cvdata = model_utils.get_cv_sets(mode, [kcv], batch_size, rc_t, resamples, rcov)[0]\n",
    "        full_model = get_full_model(datatype, cvdata, resamples, rc_t, 100, \n",
    "                                    mode, rcov, max_count, neurons)\n",
    "\n",
    "        if en > 1:\n",
    "            # predictive posterior\n",
    "            P_mc = model_utils.compute_pred_P(full_model, 0, use_neuron, None, cov_samples=10, ll_samples=1, tr=0)\n",
    "            P = P_mc.mean(0).cpu().numpy()\n",
    "\n",
    "            q_ = []\n",
    "            Z_ = []\n",
    "            for n in range(len(use_neuron)):\n",
    "                spike_binned = full_model.likelihood.spikes[0][0, use_neuron[n], :].numpy()\n",
    "                q, Z = model_utils.get_q_Z(P[n, ...], spike_binned, deq_noise=None)\n",
    "                q_.append(q)\n",
    "                Z_.append(Z)\n",
    "\n",
    "        elif en < 2:\n",
    "            _, ftrain, fcov, vtrain, vcov, cvbatch_size = cvdata\n",
    "            time_steps = ftrain.shape[-1]\n",
    "\n",
    "            cov_used = models.cov_used(mode[2], fcov)\n",
    "            q_ = model_utils.compute_count_stats(full_model, mode[1], tbin, ftrain, cov_used, list(range(neurons)), \\\n",
    "                                                 traj_len=1, start=0, T=time_steps, bs=5000)\n",
    "            Z_ = [utils.stats.q_to_Z(q) for q in q_]\n",
    "\n",
    "        Qq_rg.append(q_)\n",
    "        Zz_rg.append(Z_)\n",
    "\n",
    "    \n",
    "q_DS_rg = []\n",
    "T_DS_rg = []\n",
    "T_KS_rg = []\n",
    "for q in Qq_rg:\n",
    "    for qq in q:\n",
    "        T_DS, T_KS, sign_DS, sign_KS, p_DS, p_KS = utils.stats.KS_statistics(qq, alpha=0.05, alpha_s=0.05)\n",
    "        T_DS_rg.append(T_DS)\n",
    "        T_KS_rg.append(T_KS)\n",
    "        \n",
    "        Z_DS = T_DS/np.sqrt(2/(qq.shape[0]-1))\n",
    "        q_DS_rg.append(utils.stats.Z_to_q(Z_DS))\n",
    "\n",
    "q_DS_rg = np.array(q_DS_rg).reshape(len(CV), len(M), -1)\n",
    "T_DS_rg = np.array(T_DS_rg).reshape(len(CV), len(M), -1)\n",
    "T_KS_rg = np.array(T_KS_rg).reshape(len(CV), len(M), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aligning trajectory and computing RMS for different models\n",
    "topology = 'torus'\n",
    "cvK = 90\n",
    "CV = [15, 30, 45, 60, 75]\n",
    "Modes = modes[4:8]\n",
    "batch_size = 5000\n",
    "\n",
    "RMS_cv = []\n",
    "for mode in Modes:\n",
    "    cvdata = model_utils.get_cv_sets(mode, [-1], batch_size, rc_t, resamples, rcov)[0]\n",
    "    full_model = get_full_model(datatype, cvdata, resamples, rc_t, 100, \n",
    "                                mode, rcov, max_count, neurons)\n",
    "\n",
    "    X_loc, X_std = full_model.inputs.eval_XZ()\n",
    "    cvT = X_loc[0].shape[0]\n",
    "    tar_t = rhd_t[:cvT]\n",
    "    lat = X_loc[0]\n",
    "    \n",
    "    for rn in CV:\n",
    "        eval_range = np.arange(cvT//cvK) + rn*cvT//cvK\n",
    "\n",
    "        _, shift, sign, _, _ = utils.latent.signed_scaled_shift(lat[eval_range], tar_t[eval_range], \n",
    "                                                                topology=topology, dev=dev, learn_scale=False)\n",
    "        \n",
    "        mask = np.ones((cvT,), dtype=bool)\n",
    "        mask[eval_range] = False\n",
    "        \n",
    "        lat_t = torch.tensor((sign*lat+shift) % (2*np.pi))\n",
    "        D = (utils.latent.metric(torch.tensor(tar_t)[mask], lat_t[mask], topology)**2)\n",
    "        RMS_cv.append(np.sqrt(D.mean().item()))\n",
    "\n",
    "\n",
    "RMS_cv = np.array(RMS_cv).reshape(len(Modes), len(CV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# neuron subgroup likelihood CV for latent models\n",
    "beta = 0.0\n",
    "n_group = np.arange(5)\n",
    "ncvx = 2\n",
    "kcvs = [2, 5, 8] # validation sets chosen in 10-fold split of data\n",
    "Ms = modes[4:8]\n",
    "val_neuron = [n_group, n_group+10, n_group+20, n_group+30, n_group+40]\n",
    "\n",
    "batch_size = 5000\n",
    "LVM_cv_ll = []\n",
    "for kcv in kcvs:\n",
    "    for mode in Ms:\n",
    "        cvdata = model_utils.get_cv_sets(mode, [kcv], batch_size, rc_t, resamples, rcov)[0]\n",
    "        _, ftrain, fcov, vtrain, vcov, cvbatch_size = cvdata\n",
    "        cv_set = (ftrain, fcov, vtrain, vcov)\n",
    "        \n",
    "        for v_neuron in val_neuron:\n",
    "\n",
    "            prev_ll = np.inf\n",
    "            for tr in range(ncvx):\n",
    "                full_model = get_full_model(datatype, cvdata, resamples, rc_t, 100, \n",
    "                                            mode, rcov, max_count, neurons)\n",
    "                mask = np.ones((neurons,), dtype=bool)\n",
    "                mask[v_neuron] = False\n",
    "                f_neuron = np.arange(neurons)[mask]\n",
    "                ll = model_utils.LVM_pred_ll(full_model, mode[-5], mode[2], models.cov_used, cv_set, f_neuron, v_neuron, \n",
    "                                             beta=beta, beta_z=0.0, max_iters=3000)[0]\n",
    "                if ll < prev_ll:\n",
    "                    prev_ll = ll\n",
    "\n",
    "            LVM_cv_ll.append(prev_ll)\n",
    "        \n",
    "LVM_cv_ll = np.array(LVM_cv_ll).reshape(len(kcvs), len(Ms), len(val_neuron))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute tuning curves and latent trajectory of latent Universal model\n",
    "lat_t_ = []\n",
    "lat_std_ = []\n",
    "P_ = []\n",
    "\n",
    "comp_grate = []\n",
    "comp_gdisp = []\n",
    "comp_gFF = []\n",
    "comp_gvar = []\n",
    "\n",
    "comp_avg = []\n",
    "comp_ff = []\n",
    "comp_var = []\n",
    "\n",
    "for mode in modes[-2:]:\n",
    "    cvdata = model_utils.get_cv_sets(mode, [-1], 5000, rc_t, resamples, rcov)[0]\n",
    "    full_model = get_full_model(datatype, cvdata, resamples, rc_t, 100, \n",
    "                                mode, rcov, max_count, neurons)\n",
    "\n",
    "    # predict latents\n",
    "    X_loc, X_std = full_model.inputs.eval_XZ()\n",
    "    cvT = X_loc[0].shape[0]\n",
    "\n",
    "    lat_t, shift, sign, _, _ = utils.latent.signed_scaled_shift(X_loc[0], rhd_t[:cvT], \n",
    "                                                             dev, learn_scale=False)\n",
    "    lat_t_.append(utils.signal.WrapPi(lat_t, True))\n",
    "    lat_std_.append(X_std[0])\n",
    "\n",
    "    # P\n",
    "    steps = 100\n",
    "    covariates_aligned = [(sign*(np.linspace(0, 2*np.pi, steps)-shift)) % (2*np.pi)]\n",
    "    P_mc = model_utils.compute_P(full_model, covariates_aligned, use_neuron, MC=1000).cpu()\n",
    "\n",
    "    x_counts = torch.arange(max_count+1)\n",
    "    avg = (x_counts[None, None, None, :]*P_mc).sum(-1)\n",
    "    xcvar = ((x_counts[None, None, None, :]**2*P_mc).sum(-1)-avg**2)\n",
    "    ff = xcvar/avg\n",
    "\n",
    "    avgs = utils.signal.percentiles_from_samples(avg, percentiles=[0.05, 0.5, 0.95], \n",
    "                                                 smooth_length=5, padding_mode='circular')\n",
    "    comp_avg.append([cs_.cpu().numpy() for cs_ in avgs])\n",
    "\n",
    "    ffs = utils.signal.percentiles_from_samples(ff, percentiles=[0.05, 0.5, 0.95], \n",
    "                                                smooth_length=5, padding_mode='circular')\n",
    "    comp_ff.append([cs_.cpu().numpy() for cs_ in ffs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_run = (\n",
    "    use_neuron, covariates, P_rg, grate, gdisp, gFF, gvar, hd, ref_prob, clower, cmean, cupper, \n",
    "    avglower, avgmean, avgupper, fflower, ffmean, ffupper, varlower, varmean, varupper, \n",
    "    covariates_aligned, lat_t_, lat_std_, comp_avg, comp_ff, \n",
    "    RG_cv_ll, LVM_cv_ll, RMS_cv, \n",
    "    q_DS_rg, T_DS_rg, T_KS_rg, Qq_rg, Zz_rg, sign_DS, sign_KS, \n",
    "    max_count, tbin, rcov\n",
    ")\n",
    "\n",
    "pickle.dump(data_run, open('./saves/P1_hcmp.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39",
   "language": "python",
   "name": "python39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
