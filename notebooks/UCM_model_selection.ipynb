{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Head direction attractor network\n",
    "\n",
    "\n",
    "### Table of contents\n",
    "\n",
    "1. [**Synthetic population**](#synthetic)\n",
    "3. [**SNN**](#snn)\n",
    "4. [**RNN**](#rnn)\n",
    "\n",
    "This notebook contains analysis of different UCM hyperparameters and does model comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.13.0+cu117\n",
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.special as sps\n",
    "import scipy.stats as scstats\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../lib/\") # access to library\n",
    "sys.path.append(\"../scripts/\") # access to scripts\n",
    "\n",
    "import os\n",
    "if not os.path.exists('./saves'):\n",
    "    os.makedirs('./saves')\n",
    "    \n",
    "\n",
    "import neuroprob as nprb\n",
    "from neuroprob import utils\n",
    "\n",
    "\n",
    "device = nprb.inference.get_device(gpu=0)\n",
    "\n",
    "import models\n",
    "#import ucm_stats\n",
    "\n",
    "import pickle\n",
    "\n",
    "plt.style.use(['paper.mplstyle'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='loading'></a>\n",
    "## 1. Loading a trained model\n",
    "\n",
    "Here we specify the dataset used for training and the model architecture hyperparameters. This model is the UCM fit to observed covariates ```x_mode = 'hd-w-s-pos-t'```, meaning head direction (```hd```), angular head velocity (```w```), speed (```s```), animal $x$ and $y$ position (```pos```, two dimensions), and absolute time since the start of the recording session (```t```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/'\n",
    "data_type = 'th1'\n",
    "bin_size = 40\n",
    "\n",
    "dataset_dict = models.get_dataset(data_type, bin_size, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = '../scripts/checkpoint/'\n",
    "config_name = 'th1_U-el-4_svgp-64_X[hd-omega-speed-x-y-time]_Z[]_40K11_0d0_10f-1'\n",
    "batch_info = 500\n",
    "\n",
    "\n",
    "full_model, training_loss, fit_dict, val_dict = models.load_model(\n",
    "    config_name,\n",
    "    checkpoint_dir,\n",
    "    dataset_dict,\n",
    "    batch_info,\n",
    "    device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fed5cf80f70>]"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 245x183.75 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../scripts/checkpoint/th1_U-el-1_svgp-64_X[hd-omega-speed-x-y-time]_Z[]_40K11_0d0_10f6.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [323]\u001b[0m, in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m Ell \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m config_names:\n\u001b[0;32m---> 24\u001b[0m     full_model, training_loss, fit_dict, val_dict \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     Ell\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m     33\u001b[0m         models\u001b[38;5;241m.\u001b[39mRG_pred_ll(\n\u001b[1;32m     34\u001b[0m             full_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m         )\n\u001b[1;32m     42\u001b[0m     )\n\u001b[1;32m     44\u001b[0m Ell \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(Ell)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(cvs))\n",
      "File \u001b[0;32m~/Documents/Learning/universal-count-model/notebooks/../scripts/models.py:1043\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(config_name, checkpoint_dir, dataset_dict, batch_info, device)\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(\n\u001b[1;32m   1034\u001b[0m     config_name,\n\u001b[1;32m   1035\u001b[0m     checkpoint_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     device,\n\u001b[1;32m   1039\u001b[0m ):\n\u001b[1;32m   1040\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;124;03m    Load the model with cross-validated data structure\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1043\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1047\u001b[0m     delay, cv_run \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelay\u001b[39m\u001b[38;5;124m\"\u001b[39m], checkpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv_run\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1048\u001b[0m     config \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/scratches/ramanujan/dl543/py3_9env/lib/python3.9/site-packages/torch/serialization.py:771\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    769\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 771\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    773\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    774\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    775\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    776\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/scratches/ramanujan/dl543/py3_9env/lib/python3.9/site-packages/torch/serialization.py:270\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 270\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    272\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/scratches/ramanujan/dl543/py3_9env/lib/python3.9/site-packages/torch/serialization.py:251\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../scripts/checkpoint/th1_U-el-1_svgp-64_X[hd-omega-speed-x-y-time]_Z[]_40K11_0d0_10f6.pt'"
     ]
    }
   ],
   "source": [
    "cvs = [1, 2, 3, 5, 6, 8]\n",
    "batch_info = 500\n",
    "\n",
    "config_names = [\n",
    "    'th1_U-el-1_svgp-64_X[hd-omega-speed-x-y-time]_Z[]_40K11_0d0_10f{}'.format(cv) \n",
    "    for cv in cvs\n",
    "] + [\n",
    "    'th1_U-el-2_svgp-64_X[hd-omega-speed-x-y-time]_Z[]_40K11_0d0_10f{}'.format(cv) \n",
    "    for cv in cvs\n",
    "] + [\n",
    "    'th1_U-el-3_svgp-64_X[hd-omega-speed-x-y-time]_Z[]_40K11_0d0_10f{}'.format(cv) \n",
    "    for cv in cvs\n",
    "] + [\n",
    "    'th1_U-el-4_svgp-64_X[hd-omega-speed-x-y-time]_Z[]_40K11_0d0_10f{}'.format(cv) \n",
    "    for cv in cvs\n",
    "] + [\n",
    "    'th1_U-eq-3_svgp-64_X[hd-omega-speed-x-y-time]_Z[]_40K11_0d0_10f{}'.format(cv) \n",
    "    for cv in cvs\n",
    "]\n",
    "\n",
    "\n",
    "Ell = []\n",
    "for name in config_names:\n",
    "    full_model, training_loss, fit_dict, val_dict = models.load_model(\n",
    "        name,\n",
    "        checkpoint_dir,\n",
    "        dataset_dict,\n",
    "        batch_info,\n",
    "        device,\n",
    "    )\n",
    "    \n",
    "    Ell.append(\n",
    "        models.RG_pred_ll(\n",
    "            full_model,\n",
    "            val_dict,\n",
    "            neuron_group=None,\n",
    "            ll_mode=\"GH\",\n",
    "            ll_samples=100,\n",
    "            cov_samples=1,\n",
    "            beta=0.0,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "Ell = np.array(Ell).reshape(-1, len(cvs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ErrorbarContainer object of 3 artists>"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 245x183.75 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.errorbar(np.arange(Ell.shape[0]), Ell.mean(-1), yerr=Ell.std(-1) / np.sqrt(len(cvs)), capsize=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _bumps:\n",
    "    @staticmethod\n",
    "    def HDC_bumps(theta, A, invbeta, b, theta_0):\n",
    "        \"\"\"\n",
    "        parameters have shape (neurons,)\n",
    "        :return:\n",
    "            rates of shape (..., neurons, eval_pts)\n",
    "        \"\"\"\n",
    "        return A[:, None] * np.exp(\n",
    "            np.cos(theta[..., None, :] - theta_0[:, None]) / invbeta[:, None]) + b[:, None]\n",
    "\n",
    "    \n",
    "class hCMP_bumps(_bumps):\n",
    "    \"\"\"\n",
    "    CMP with separate mu and nu parameter tuning curves\n",
    "    \"\"\"\n",
    "    def __init__(self, rng, neurons):\n",
    "        # rate tuning curves\n",
    "        self.angle_0 = np.linspace(0, 2 * np.pi, neurons + 1)[:-1]\n",
    "        self.beta = rng.uniform(size=(neurons,)) * 2.0 + 0.5\n",
    "        self.rate_0 = rng.uniform(size=(neurons,)) * 4.0 + 4.0\n",
    "        self.b = rng.uniform(size=(neurons,)) * 0.1\n",
    "\n",
    "        # dispersion tuning curve\n",
    "        self._angle_0 = rng.permutation(self.angle_0)\n",
    "        self._beta = 0.3 * rng.uniform(size=(neurons,)) + 0.1\n",
    "        self._rate_0 = rng.uniform(size=(neurons,)) * 0.5 + 0.6\n",
    "        self._b = rng.uniform(size=(neurons,)) * 0.1\n",
    "        \n",
    "    def __call__(self, covariates, sample_bin):\n",
    "        theta = covariates[..., 0]\n",
    "        mu = _bumps.HDC_bumps(theta, self.rate_0, 1/self.beta, self.b, self.angle_0)\n",
    "        nu = _bumps.HDC_bumps(theta, self._rate_0, 1/self._beta, self._b, self._angle_0)\n",
    "        \n",
    "        lamb = np.maximum(mu*sample_bin + .5 * (1 - 1/nu), 0.)**(nu)  # threshold as expression is approximate\n",
    "        return lamb, nu  # (..., neurons, ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = hCMP_bumps(rng, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamb, nu = m(np.linspace(0., 2*np.pi, 100)[:, None], 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 245x183.75 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 245x183.75 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lamb[0, :])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(nu[3, :])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/'\n",
    "data_type = 'hCMP1'\n",
    "bin_size = 1\n",
    "\n",
    "dataset_dict = models.get_dataset(data_type, bin_size, data_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatype = 1\n",
    "rcov, neurons, tbin, resamples, rc_t = validation.get_dataset(datatype, '../scripts/data')\n",
    "max_count = int(rc_t.max())\n",
    "trials = 1\n",
    "\n",
    "use_neuron = np.arange(50)\n",
    "\n",
    "\n",
    "rhd_t = rcov[0]\n",
    "ra_t = rcov[1]\n",
    "covariates = [rhd_t[None, :, None].repeat(trials, axis=0), \n",
    "              ra_t[None, :, None].repeat(trials, axis=0)]\n",
    "glm = validation.IP_bumps(tbin, resamples, covariates, neurons, trials=trials)\n",
    "glm.to(dev)\n",
    "\n",
    "checkpoint = torch.load('../scripts/data/IP_HDC_model', map_location='cuda:0')\n",
    "glm.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = [('GP', 'IP', 'hd', 8, 'exp', 1, [], False, 10, False, 'ew'), \n",
    "         ('GP', 'U', 'hd', 8, 'identity', 3, [], False, 10, False, 'ew'),\n",
    "         ('GP', 'U', 'hdxR1', 16, 'identity', 3, [1], False, 10, False, 'ew')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# neuron subgroup likelihood CV\n",
    "beta = 0.0\n",
    "n_group = np.arange(5)\n",
    "val_neuron = [n_group, n_group+10, n_group+20, n_group+30, n_group+40]\n",
    "ncvx = 2\n",
    "kcvs = [2, 5, 8] # validation sets chosen in 10-fold split of data\n",
    "Ms = modes[:3]\n",
    "\n",
    "batch_size = 5000\n",
    "cv_pll = []\n",
    "for em, mode in enumerate(Ms):\n",
    "    for cvdata in model_utils.get_cv_sets(mode, kcvs, batch_size, rc_t, resamples, rcov):\n",
    "        _, ftrain, fcov, vtrain, vcov, cvbatch_size = cvdata\n",
    "        cv_set = (ftrain, fcov, vtrain, vcov)\n",
    "        \n",
    "        if em > 1:\n",
    "            for v_neuron in val_neuron:\n",
    "\n",
    "                prev_ll = np.inf\n",
    "                for tr in range(ncvx):\n",
    "                    full_model = get_full_model(datatype, cvdata, resamples, rc_t, 100, \n",
    "                                                mode, rcov, max_count, neurons)\n",
    "                    mask = np.ones((neurons,), dtype=bool)\n",
    "                    mask[v_neuron] = False\n",
    "                    f_neuron = np.arange(neurons)[mask]\n",
    "                    ll = model_utils.LVM_pred_ll(full_model, mode[-5], mode[2], models.cov_used, cv_set, f_neuron, v_neuron, \n",
    "                                                 beta=beta, beta_z=0.0, max_iters=3000)[0]\n",
    "                    if ll < prev_ll:\n",
    "                        prev_ll = ll\n",
    "\n",
    "                cv_pll.append(prev_ll)\n",
    "                \n",
    "        else:\n",
    "            for v_neuron in val_neuron:\n",
    "                full_model = get_full_model(datatype, cvdata, resamples, rc_t, 100, \n",
    "                                            mode, rcov, max_count, neurons)\n",
    "                cv_pll.append(model_utils.RG_pred_ll(full_model, mode[2], models.cov_used, cv_set, bound='ELBO', \n",
    "                                                     beta=beta, neuron_group=v_neuron, ll_mode='GH', ll_samples=100))\n",
    "\n",
    "        \n",
    "cv_pll = np.array(cv_pll).reshape(len(Ms), len(kcvs), len(val_neuron))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute tuning curves and latent trajectories for XZ joint regression-latent model\n",
    "mode = modes[2]\n",
    "cvdata = model_utils.get_cv_sets(mode, [-1], 5000, rc_t, resamples, rcov)[0]\n",
    "\n",
    "full_model = get_full_model(datatype, cvdata, resamples, rc_t, 100, \n",
    "                            mode, rcov, max_count, neurons)\n",
    "\n",
    "# latents\n",
    "X_loc, X_std = full_model.inputs.eval_XZ()\n",
    "\n",
    "T = X_loc[1].shape[0]\n",
    "X_c, shift, sign, scale, _ = utils.latent.signed_scaled_shift(X_loc[1], ra_t[:T], \n",
    "                                                              dev, 'euclid', learn_scale=True)\n",
    "X_s = scale*X_std[1]\n",
    "\n",
    "\n",
    "\n",
    "# tuning\n",
    "steps = 100\n",
    "covariates_z = [0.*np.ones(steps), np.linspace(X_loc[1].min(), X_loc[1].max(), steps)]\n",
    "P_mc = model_utils.compute_P(full_model, covariates_z, use_neuron, MC=1000).cpu()\n",
    "\n",
    "x_counts = torch.arange(max_count+1)\n",
    "avg = (x_counts[None, None, None, :]*P_mc).sum(-1)\n",
    "xcvar = ((x_counts[None, None, None, :]**2*P_mc).sum(-1)-avg**2)\n",
    "ff = xcvar/avg\n",
    "\n",
    "avgs = utils.signal.percentiles_from_samples(avg, percentiles=[0.05, 0.5, 0.95], \n",
    "                                             smooth_length=5, padding_mode='replicate')\n",
    "avglower, avgmean, avgupper = [cs_.cpu().numpy() for cs_ in avgs]\n",
    "\n",
    "ffs = utils.signal.percentiles_from_samples(ff, percentiles=[0.05, 0.5, 0.95], \n",
    "                                            smooth_length=5, padding_mode='replicate')\n",
    "fflower, ffmean, ffupper = [cs_.cpu().numpy() for cs_ in ffs]\n",
    "\n",
    "\n",
    "covariates_z[1] = sign*scale*covariates_z[1]+shift\n",
    "grate = glm.mapping.eval_rate(covariates_z, use_neuron)[0, ...]\n",
    "gFF = np.ones_like(grate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KS framework\n",
    "Qq = []\n",
    "Zz = []\n",
    "R = []\n",
    "Rp = []\n",
    "\n",
    "batch_size = 5000\n",
    "\n",
    "Ms = modes[:3]\n",
    "CV = [2, 5, 8]\n",
    "for kcv in CV:\n",
    "    for en, mode in enumerate(Ms):\n",
    "        cvdata = model_utils.get_cv_sets(mode, [kcv], batch_size, rc_t, resamples, rcov)[0]\n",
    "        _, ftrain, fcov, vtrain, vcov, cvbatch_size = cvdata\n",
    "        time_steps = ftrain.shape[-1]\n",
    "            \n",
    "        full_model = get_full_model(datatype, cvdata, resamples, rc_t, 100, \n",
    "                                    mode, rcov, max_count, neurons)\n",
    "\n",
    "        if en > 0:\n",
    "            # predictive posterior\n",
    "            q_ = []\n",
    "            Z_ = []\n",
    "            for b in range(full_model.inputs.batches):\n",
    "                P_mc = model_utils.compute_pred_P(full_model, b, use_neuron, None, cov_samples=10, ll_samples=1, tr=0)\n",
    "                P = P_mc.mean(0).cpu().numpy()\n",
    "\n",
    "                for n in range(len(use_neuron)):\n",
    "                    spike_binned = full_model.likelihood.spikes[b][0, n, :].numpy()\n",
    "                    q, Z = model_utils.get_q_Z(P[n, ...], spike_binned, deq_noise=None)\n",
    "\n",
    "                    if b == 0:\n",
    "                        q_.append(q)\n",
    "                        Z_.append(Z)\n",
    "                    else:\n",
    "                        q_[n] = np.concatenate((q_[n], q))\n",
    "                        Z_[n] = np.concatenate((Z_[n], Z))\n",
    "\n",
    "        elif en == 0:\n",
    "            cov_used = models.cov_used(mode[2], fcov)\n",
    "            q_ = model_utils.compute_count_stats(full_model, 'IP', tbin, ftrain, cov_used, use_neuron, \\\n",
    "                                                 traj_len=1, start=0, T=time_steps, bs=5000)\n",
    "            Z_ = [utils.stats.q_to_Z(q) for q in q_]\n",
    "\n",
    "\n",
    "        Pearson_s = []\n",
    "        for n in range(len(use_neuron)):\n",
    "            for m in range(n+1, len(use_neuron)):\n",
    "                r, r_p = scstats.pearsonr(Z_[n], Z_[m]) # Pearson r correlation test\n",
    "                Pearson_s.append((r, r_p))\n",
    "\n",
    "        r = np.array([p[0] for p in Pearson_s])\n",
    "        r_p = np.array([p[1] for p in Pearson_s])\n",
    "\n",
    "        Qq.append(q_)\n",
    "        Zz.append(Z_)\n",
    "        R.append(r)\n",
    "        Rp.append(r_p)\n",
    "\n",
    "    \n",
    "    \n",
    "fisher_z = []\n",
    "fisher_q = []\n",
    "for en, r in enumerate(R):\n",
    "    fz = 0.5*np.log((1+r)/(1-r))*np.sqrt(time_steps-3)\n",
    "    fisher_z.append(fz)\n",
    "    fisher_q.append(utils.stats.Z_to_q(fz))\n",
    "    \n",
    "    \n",
    "    \n",
    "q_DS_ = []\n",
    "T_DS_ = []\n",
    "T_KS_ = []\n",
    "for q in Qq:\n",
    "    for qq in q:\n",
    "        T_DS, T_KS, sign_DS, sign_KS, p_DS, p_KS = utils.stats.KS_statistics(qq, alpha=0.05, alpha_s=0.05)\n",
    "        T_DS_.append(T_DS)\n",
    "        T_KS_.append(T_KS)\n",
    "        \n",
    "        Z_DS = T_DS/np.sqrt(2/(qq.shape[0]-1))\n",
    "        q_DS_.append(utils.stats.Z_to_q(Z_DS))\n",
    "\n",
    "\n",
    "q_DS_ = np.array(q_DS_).reshape(len(CV), len(Ms), -1)\n",
    "T_DS_ = np.array(T_DS_).reshape(len(CV), len(Ms), -1)\n",
    "T_KS_ = np.array(T_KS_).reshape(len(CV), len(Ms), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise correlation structure\n",
    "NN = len(use_neuron)\n",
    "R_mat_Xp = np.zeros((NN, NN))\n",
    "R_mat_X = np.zeros((NN, NN))\n",
    "R_mat_XZ = np.zeros((NN, NN))\n",
    "for a in range(len(R[0])):\n",
    "    n, m = model_utils.ind_to_pair(a, NN)\n",
    "    R_mat_Xp[n, m] = R[0][a]\n",
    "    R_mat_X[n, m] = R[1][a]\n",
    "    R_mat_XZ[n, m] = R[2][a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_run = (\n",
    "    q_DS_, T_DS_, T_KS_, sign_DS, fisher_z, fisher_q, Qq, Zz, \n",
    "    R, Rp, X_c, X_s, ra_t, R_mat_Xp, R_mat_X, R_mat_XZ, cv_pll, \n",
    "    covariates_z, avglower, avgmean, avgupper, fflower, ffmean, ffupper, \n",
    "    grate, gFF, \n",
    "    use_neuron, max_count, tbin, rcov\n",
    ")\n",
    "\n",
    "pickle.dump(data_run, open('./saves/P2.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hCMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = [('GP', 'IP', 'hd', 8, 'exp', 1, [], False, 10, False, 'ew'), \n",
    "         ('GP', 'hNB', 'hd', 8, 'exp', 1, [], False, 10, False, 'ew'), \n",
    "         ('GP', 'U', 'hd', 8, 'identity', 3, [], False, 10, False, 'ew'), \n",
    "         ('ANN', 'U', 'hd', 8, 'identity', 3, [], False, 10, False, 'ew'), \n",
    "         ('GP', 'IP', 'T1', 8, 'exp', 1, [0], False, 10, False, 'ew'), \n",
    "         ('GP', 'hNB', 'T1', 8, 'exp', 1, [0], False, 10, False, 'ew'), \n",
    "         ('GP', 'U', 'T1', 8, 'identity', 3, [0], False, 10, False, 'ew'), \n",
    "         ('ANN', 'U', 'T1', 8, 'identity', 3, [0], False, 10, False, 'ew')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatype = 0\n",
    "rcov, neurons, tbin, resamples, rc_t = validation.get_dataset(datatype, '../scripts/data')\n",
    "max_count = int(rc_t.max())\n",
    "\n",
    "use_neuron = list(range(neurons))\n",
    "\n",
    "\n",
    "rhd_t = rcov[0]\n",
    "trials = 1\n",
    "covariates = [rhd_t[None, :, None].repeat(trials, axis=0)]\n",
    "glm = validation.CMP_hdc(tbin, resamples, covariates, neurons, trials=trials)\n",
    "glm.to(dev)\n",
    "\n",
    "checkpoint = torch.load('../scripts/data/hCMP_HDC_model', map_location='cpu')\n",
    "\n",
    "glm.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-validation of regression models\n",
    "beta = 0.0\n",
    "kcvs = [2, 5, 8] # validation sets chosen in 10-fold split of data\n",
    "batch_size = 5000\n",
    "\n",
    "Ms = modes[:4]\n",
    "RG_cv_ll = []\n",
    "for mode in Ms:\n",
    "    for cvdata in model_utils.get_cv_sets(mode, kcvs, batch_size, rc_t, resamples, rcov):\n",
    "        _, ftrain, fcov, vtrain, vcov, cvbatch_size = cvdata\n",
    "        cv_set = (ftrain, fcov, vtrain, vcov)\n",
    "        \n",
    "        full_model = get_full_model(datatype, cvdata, resamples, rc_t, 100, \n",
    "                                    mode, rcov, max_count, neurons)\n",
    "        RG_cv_ll.append(model_utils.RG_pred_ll(full_model, mode[2], models.cov_used, cv_set, bound='ELBO', \n",
    "                                               beta=beta, neuron_group=None, ll_mode='GH', ll_samples=100))\n",
    "    \n",
    "RG_cv_ll = np.array(RG_cv_ll).reshape(len(Ms), len(kcvs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute tuning curves of ground truth model\n",
    "batch_size = 5000\n",
    "\n",
    "cvdata = model_utils.get_cv_sets(mode, [2], batch_size, rc_t, resamples, rcov)[0]\n",
    "full_model = get_full_model(datatype, cvdata, resamples, rc_t, 100, \n",
    "                            modes[2], rcov, max_count, neurons)\n",
    "\n",
    "\n",
    "\n",
    "steps = 100\n",
    "covariates = [np.linspace(0, 2*np.pi, steps)]\n",
    "P_mc = model_utils.compute_P(full_model, covariates, use_neuron, MC=1000)\n",
    "P_rg = P_mc.mean(0).cpu().numpy()\n",
    "\n",
    "x_counts = torch.arange(max_count+1)\n",
    "\n",
    "\n",
    "\n",
    "mu = glm.mapping.eval_rate(covariates, use_neuron)[0:1, ...] # mu is the rate, so need to multiply by tbin\n",
    "log_nu = glm.likelihood.dispersion_mapping.eval_rate(covariates, use_neuron)[0:1, ...]\n",
    "\n",
    "log_mudt = torch.tensor(np.log(mu*tbin)).to(dev)\n",
    "nu = torch.tensor(np.exp(log_nu)).to(dev)\n",
    "\n",
    "AD = False # using Autograd for computing the CMP partition function is slow...\n",
    "if AD: # differentiate the partition function\n",
    "    t = torch.tensor(0.).to(dev)\n",
    "    t.requires_grad = True\n",
    "    log_Z = glm.likelihood.log_Z(log_mu+t, nu)\n",
    "\n",
    "    grad_t = torch.empty(log_Z.shape)\n",
    "    ggrad_t = torch.empty(log_Z.shape)\n",
    "    for n in use_neuron:\n",
    "        print(n)\n",
    "        for s in range(steps):\n",
    "            ind = torch.zeros_like(log_Z)\n",
    "            ind[0, n, s] = 1.\n",
    "            grad_t_, = torch.autograd.grad(log_Z, t, ind, retain_graph=True, create_graph=True)\n",
    "            grad_t[0, n, s] = grad_t_\n",
    "\n",
    "            ggrad_t_, = torch.autograd.grad(grad_t_, t, retain_graph=True, create_graph=True)\n",
    "            ggrad_t[0, n, s] = ggrad_t_\n",
    "\n",
    "\n",
    "    gmean = grad_t.data.cpu().numpy()[0, ...]\n",
    "    gvar = ggrad_t.data.cpu().numpy()[0, ...]\n",
    "\n",
    "else: # compute the partition function explicitly\n",
    "    gmean = utils.stats.cmp_moments(1, mu[0, ...], nu.cpu().numpy()[0, ...], tbin, J=10000)\n",
    "    gvar = utils.stats.cmp_moments(2, mu[0, ...], nu.cpu().numpy()[0, ...], tbin, J=10000) - gmean**2\n",
    "    \n",
    "grate = mu[0, ...]\n",
    "gdisp = nu.cpu().numpy()[0, ...]\n",
    "gFF = gvar/gmean\n",
    "\n",
    "\n",
    "\n",
    "# compute tuning curves and SCDs for model fit\n",
    "ref_prob = []\n",
    "hd = [20, 50, 80]\n",
    "for hd_ in hd:\n",
    "    for n in range(len(use_neuron)):\n",
    "        ref_prob.append([utils.stats.cmp_count_prob(xc, grate[n, hd_], gdisp[n, hd_], tbin) for xc in x_counts.numpy()])\n",
    "ref_prob = np.array(ref_prob).reshape(len(hd), len(use_neuron), -1)\n",
    "\n",
    "cs = utils.signal.percentiles_from_samples(P_mc[..., hd, :], percentiles=[0.05, 0.5, 0.95], smooth_length=1)\n",
    "clower, cmean, cupper = [cs_.cpu().numpy() for cs_ in cs]\n",
    "\n",
    "\n",
    "avg = (x_counts[None, None, None, :]*P_mc.cpu()).sum(-1)\n",
    "xcvar = ((x_counts[None, None, None, :]**2*P_mc.cpu()).sum(-1)-avg**2)\n",
    "ff = xcvar/avg\n",
    "\n",
    "avgs = utils.signal.percentiles_from_samples(avg, percentiles=[0.05, 0.5, 0.95], \n",
    "                                             smooth_length=5, padding_mode='circular')\n",
    "avglower, avgmean, avgupper = [cs_.cpu().numpy() for cs_ in avgs]\n",
    "\n",
    "ffs = utils.signal.percentiles_from_samples(ff, percentiles=[0.05, 0.5, 0.95], \n",
    "                                            smooth_length=5, padding_mode='circular')\n",
    "fflower, ffmean, ffupper = [cs_.cpu().numpy() for cs_ in ffs]\n",
    "\n",
    "xcvars = utils.signal.percentiles_from_samples(xcvar, percentiles=[0.05, 0.5, 0.95], \n",
    "                                               smooth_length=5, padding_mode='circular')\n",
    "varlower, varmean, varupper = [cs_.cpu().numpy() for cs_ in xcvars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# KS framework\n",
    "Qq_rg = []\n",
    "Zz_rg = []\n",
    "\n",
    "batch_size = 5000\n",
    "M = modes[:4]\n",
    "CV = [2, 5, 8]\n",
    "for kcv in CV:\n",
    "    for en, mode in enumerate(M):\n",
    "        cvdata = model_utils.get_cv_sets(mode, [kcv], batch_size, rc_t, resamples, rcov)[0]\n",
    "        full_model = get_full_model(datatype, cvdata, resamples, rc_t, 100, \n",
    "                                    mode, rcov, max_count, neurons)\n",
    "\n",
    "        if en > 1:\n",
    "            # predictive posterior\n",
    "            P_mc = model_utils.compute_pred_P(full_model, 0, use_neuron, None, cov_samples=10, ll_samples=1, tr=0)\n",
    "            P = P_mc.mean(0).cpu().numpy()\n",
    "\n",
    "            q_ = []\n",
    "            Z_ = []\n",
    "            for n in range(len(use_neuron)):\n",
    "                spike_binned = full_model.likelihood.spikes[0][0, use_neuron[n], :].numpy()\n",
    "                q, Z = model_utils.get_q_Z(P[n, ...], spike_binned, deq_noise=None)\n",
    "                q_.append(q)\n",
    "                Z_.append(Z)\n",
    "\n",
    "        elif en < 2:\n",
    "            _, ftrain, fcov, vtrain, vcov, cvbatch_size = cvdata\n",
    "            time_steps = ftrain.shape[-1]\n",
    "\n",
    "            cov_used = models.cov_used(mode[2], fcov)\n",
    "            q_ = model_utils.compute_count_stats(full_model, mode[1], tbin, ftrain, cov_used, list(range(neurons)), \\\n",
    "                                                 traj_len=1, start=0, T=time_steps, bs=5000)\n",
    "            Z_ = [utils.stats.q_to_Z(q) for q in q_]\n",
    "\n",
    "        Qq_rg.append(q_)\n",
    "        Zz_rg.append(Z_)\n",
    "\n",
    "    \n",
    "q_DS_rg = []\n",
    "T_DS_rg = []\n",
    "T_KS_rg = []\n",
    "for q in Qq_rg:\n",
    "    for qq in q:\n",
    "        T_DS, T_KS, sign_DS, sign_KS, p_DS, p_KS = utils.stats.KS_statistics(qq, alpha=0.05, alpha_s=0.05)\n",
    "        T_DS_rg.append(T_DS)\n",
    "        T_KS_rg.append(T_KS)\n",
    "        \n",
    "        Z_DS = T_DS/np.sqrt(2/(qq.shape[0]-1))\n",
    "        q_DS_rg.append(utils.stats.Z_to_q(Z_DS))\n",
    "\n",
    "q_DS_rg = np.array(q_DS_rg).reshape(len(CV), len(M), -1)\n",
    "T_DS_rg = np.array(T_DS_rg).reshape(len(CV), len(M), -1)\n",
    "T_KS_rg = np.array(T_KS_rg).reshape(len(CV), len(M), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aligning trajectory and computing RMS for different models\n",
    "topology = 'torus'\n",
    "cvK = 90\n",
    "CV = [15, 30, 45, 60, 75]\n",
    "Modes = modes[4:8]\n",
    "batch_size = 5000\n",
    "\n",
    "RMS_cv = []\n",
    "for mode in Modes:\n",
    "    cvdata = model_utils.get_cv_sets(mode, [-1], batch_size, rc_t, resamples, rcov)[0]\n",
    "    full_model = get_full_model(datatype, cvdata, resamples, rc_t, 100, \n",
    "                                mode, rcov, max_count, neurons)\n",
    "\n",
    "    X_loc, X_std = full_model.inputs.eval_XZ()\n",
    "    cvT = X_loc[0].shape[0]\n",
    "    tar_t = rhd_t[:cvT]\n",
    "    lat = X_loc[0]\n",
    "    \n",
    "    for rn in CV:\n",
    "        eval_range = np.arange(cvT//cvK) + rn*cvT//cvK\n",
    "\n",
    "        _, shift, sign, _, _ = utils.latent.signed_scaled_shift(lat[eval_range], tar_t[eval_range], \n",
    "                                                                topology=topology, dev=dev, learn_scale=False)\n",
    "        \n",
    "        mask = np.ones((cvT,), dtype=bool)\n",
    "        mask[eval_range] = False\n",
    "        \n",
    "        lat_t = torch.tensor((sign*lat+shift) % (2*np.pi))\n",
    "        D = (utils.latent.metric(torch.tensor(tar_t)[mask], lat_t[mask], topology)**2)\n",
    "        RMS_cv.append(np.sqrt(D.mean().item()))\n",
    "\n",
    "\n",
    "RMS_cv = np.array(RMS_cv).reshape(len(Modes), len(CV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# neuron subgroup likelihood CV for latent models\n",
    "beta = 0.0\n",
    "n_group = np.arange(5)\n",
    "ncvx = 2\n",
    "kcvs = [2, 5, 8] # validation sets chosen in 10-fold split of data\n",
    "Ms = modes[4:8]\n",
    "val_neuron = [n_group, n_group+10, n_group+20, n_group+30, n_group+40]\n",
    "\n",
    "batch_size = 5000\n",
    "LVM_cv_ll = []\n",
    "for kcv in kcvs:\n",
    "    for mode in Ms:\n",
    "        cvdata = model_utils.get_cv_sets(mode, [kcv], batch_size, rc_t, resamples, rcov)[0]\n",
    "        _, ftrain, fcov, vtrain, vcov, cvbatch_size = cvdata\n",
    "        cv_set = (ftrain, fcov, vtrain, vcov)\n",
    "        \n",
    "        for v_neuron in val_neuron:\n",
    "\n",
    "            prev_ll = np.inf\n",
    "            for tr in range(ncvx):\n",
    "                full_model = get_full_model(datatype, cvdata, resamples, rc_t, 100, \n",
    "                                            mode, rcov, max_count, neurons)\n",
    "                mask = np.ones((neurons,), dtype=bool)\n",
    "                mask[v_neuron] = False\n",
    "                f_neuron = np.arange(neurons)[mask]\n",
    "                ll = model_utils.LVM_pred_ll(full_model, mode[-5], mode[2], models.cov_used, cv_set, f_neuron, v_neuron, \n",
    "                                             beta=beta, beta_z=0.0, max_iters=3000)[0]\n",
    "                if ll < prev_ll:\n",
    "                    prev_ll = ll\n",
    "\n",
    "            LVM_cv_ll.append(prev_ll)\n",
    "        \n",
    "LVM_cv_ll = np.array(LVM_cv_ll).reshape(len(kcvs), len(Ms), len(val_neuron))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute tuning curves and latent trajectory of latent Universal model\n",
    "lat_t_ = []\n",
    "lat_std_ = []\n",
    "P_ = []\n",
    "\n",
    "comp_grate = []\n",
    "comp_gdisp = []\n",
    "comp_gFF = []\n",
    "comp_gvar = []\n",
    "\n",
    "comp_avg = []\n",
    "comp_ff = []\n",
    "comp_var = []\n",
    "\n",
    "for mode in modes[-2:]:\n",
    "    cvdata = model_utils.get_cv_sets(mode, [-1], 5000, rc_t, resamples, rcov)[0]\n",
    "    full_model = get_full_model(datatype, cvdata, resamples, rc_t, 100, \n",
    "                                mode, rcov, max_count, neurons)\n",
    "\n",
    "    # predict latents\n",
    "    X_loc, X_std = full_model.inputs.eval_XZ()\n",
    "    cvT = X_loc[0].shape[0]\n",
    "\n",
    "    lat_t, shift, sign, _, _ = utils.latent.signed_scaled_shift(X_loc[0], rhd_t[:cvT], \n",
    "                                                             dev, learn_scale=False)\n",
    "    lat_t_.append(utils.signal.WrapPi(lat_t, True))\n",
    "    lat_std_.append(X_std[0])\n",
    "\n",
    "    # P\n",
    "    steps = 100\n",
    "    covariates_aligned = [(sign*(np.linspace(0, 2*np.pi, steps)-shift)) % (2*np.pi)]\n",
    "    P_mc = model_utils.compute_P(full_model, covariates_aligned, use_neuron, MC=1000).cpu()\n",
    "\n",
    "    x_counts = torch.arange(max_count+1)\n",
    "    avg = (x_counts[None, None, None, :]*P_mc).sum(-1)\n",
    "    xcvar = ((x_counts[None, None, None, :]**2*P_mc).sum(-1)-avg**2)\n",
    "    ff = xcvar/avg\n",
    "\n",
    "    avgs = utils.signal.percentiles_from_samples(avg, percentiles=[0.05, 0.5, 0.95], \n",
    "                                                 smooth_length=5, padding_mode='circular')\n",
    "    comp_avg.append([cs_.cpu().numpy() for cs_ in avgs])\n",
    "\n",
    "    ffs = utils.signal.percentiles_from_samples(ff, percentiles=[0.05, 0.5, 0.95], \n",
    "                                                smooth_length=5, padding_mode='circular')\n",
    "    comp_ff.append([cs_.cpu().numpy() for cs_ in ffs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_run = (\n",
    "    use_neuron, covariates, P_rg, grate, gdisp, gFF, gvar, hd, ref_prob, clower, cmean, cupper, \n",
    "    avglower, avgmean, avgupper, fflower, ffmean, ffupper, varlower, varmean, varupper, \n",
    "    covariates_aligned, lat_t_, lat_std_, comp_avg, comp_ff, \n",
    "    RG_cv_ll, LVM_cv_ll, RMS_cv, \n",
    "    q_DS_rg, T_DS_rg, T_KS_rg, Qq_rg, Zz_rg, sign_DS, sign_KS, \n",
    "    max_count, tbin, rcov\n",
    ")\n",
    "\n",
    "pickle.dump(data_run, open('./saves/P1_hcmp.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39",
   "language": "python",
   "name": "python39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
