{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCM spike count distribution marginalization\n",
    "\n",
    "Here we compare UCM models with larger number of input covariates that have been marginalized to smaller numbers of input covariates with UCM models of the smaller input spaces.\n",
    "\n",
    "```\n",
    "python3 models.py --data_type th1 --checkpoint_dir ./checkpoint/ --data_path ../data/ --cv_folds 10 --cv -1 1 2 3 5 6 8 --seeds 123 1234 12345 --batch_size 10000 --max_epochs 3000 --bin_size 40 --likelihood U-el-3 --mapping svgp-32 --x_mode hd --lr 1e-2 --jitter 1e-5 --gpu 0\n",
    "\n",
    "python3 models.py --data_type th1 --checkpoint_dir ./checkpoint/ --data_path ../data/ --cv_folds 10 --cv -1 1 2 3 5 6 8 --seeds 123 1234 12345 --batch_size 10000 --max_epochs 3000 --bin_size 40 --likelihood U-el-3 --mapping svgp-32 --x_mode x-y --lr 1e-2 --jitter 1e-5 --gpu 0\n",
    "\n",
    "python3 models.py --data_type th1 --checkpoint_dir ./checkpoint/ --data_path ../data/ --cv_folds 10 --cv -1 1 2 3 5 6 8 --seeds 123 1234 12345 --batch_size 10000 --max_epochs 3000 --bin_size 40 --likelihood U-el-3 --mapping svgp-32 --x_mode hd-x-y --lr 1e-2 --jitter 1e-5 --gpu 1\n",
    "```\n",
    "\n",
    "### Table of contents\n",
    "\n",
    "1. [**Loading UCM models**](#load)\n",
    "2. [**Marginalized UCM comparison**](#marg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.13.1+cu117\n",
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.special as sps\n",
    "import scipy.stats as scstats\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") # access to library\n",
    "sys.path.append(\"../scripts/\") # access to scripts\n",
    "    \n",
    "\n",
    "import neuroprob as nprb\n",
    "from neuroprob import utils\n",
    "\n",
    "\n",
    "device = nprb.inference.get_device(gpu=0)\n",
    "\n",
    "import models\n",
    "#import ucm_stats\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='loading'></a>\n",
    "## 1. Loading UCM models\n",
    "\n",
    "Here we specify the dataset used for training and the model architecture hyperparameters. This model is the UCM fit to observed covariates ```x_mode = 'hd-w-s-pos-t'```, meaning head direction (```hd```), angular head velocity (```w```), speed (```s```), animal $x$ and $y$ position (```pos```, two dimensions), and absolute time since the start of the recording session (```t```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/'\n",
    "data_type = 'th1'\n",
    "bin_size = 40\n",
    "\n",
    "dataset_dict = models.get_dataset(data_type, bin_size, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = '../scripts/checkpoint/'\n",
    "batch_info = 500\n",
    "training_losses = []\n",
    "\n",
    "config_name = 'th1_U-el-3_svgp-32_X[hd-x-y]_Z[]_40K11_0d0_10f1'\n",
    "\n",
    "full_model, training_loss, fit_dict, _ = models.load_model(\n",
    "    config_name,\n",
    "    checkpoint_dir,\n",
    "    dataset_dict,\n",
    "    batch_info,\n",
    "    'cpu', \n",
    ")\n",
    "training_losses.append(training_loss)\n",
    "\n",
    "\n",
    "config_name = 'th1_U-el-3_svgp-32_X[hd]_Z[]_40K11_0d0_10f1'\n",
    "\n",
    "hd_model, training_loss, _, _ = models.load_model(\n",
    "    config_name,\n",
    "    checkpoint_dir,\n",
    "    dataset_dict,\n",
    "    batch_info,\n",
    "    'cpu', \n",
    ")\n",
    "training_losses.append(training_loss)\n",
    "\n",
    "\n",
    "# config_name = 'th1_U-el-3_svgp-32_X[x-y]_Z[]_40K11_0d0_10f1'\n",
    "\n",
    "# xy_model, training_loss, _, _ = models.load_model(\n",
    "#     config_name,\n",
    "#     checkpoint_dir,\n",
    "#     dataset_dict,\n",
    "#     batch_info,\n",
    "#     'cpu', \n",
    "# )\n",
    "# training_losses.append(training_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for training_loss in training_losses:\n",
    "    plt.plot(training_loss)\n",
    "    plt.yscale('log')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='marg'></a>\n",
    "## 2. Marginalized UCM comparison\n",
    "\n",
    "Here we specify the dataset used for training and the model architecture hyperparameters. This model is the UCM fit to observed covariates ```x_mode = 'hd-w-s-pos-t'```, meaning head direction (```hd```), angular head velocity (```w```), speed (```s```), animal $x$ and $y$ position (```pos```, two dimensions), and absolute time since the start of the recording session (```t```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eea7ab1c18f41dbb286304d8d3c3b49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compare to model fit only to hd\n",
    "skip = 1\n",
    "MC = 100\n",
    "pick_neurons = [0]\n",
    "batch_size = 1000\n",
    "eval_steps = 100\n",
    "\n",
    "full_model = full_model.to('cpu')  # move to GPU if possible\n",
    "\n",
    "P_tot = utils.model.marginalize_UCM_P_count(\n",
    "    full_model.mapping,\n",
    "    full_model.likelihood, \n",
    "    [torch.linspace(0, 2 * np.pi, eval_steps)],\n",
    "    [0],\n",
    "    fit_dict['covariates'],\n",
    "    batch_size,\n",
    "    pick_neurons,\n",
    "    MC=MC,\n",
    "    sample_skip=skip,\n",
    ")\n",
    "\n",
    "full_model = full_model.to('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantiles, Z scores\n",
    "P_ = []\n",
    "for b in range(gpr.input_group.batches):\n",
    "    covariates, _ = gpr.input_group.sample_XZ(b, samples=1)  # get the training batch b\n",
    "    with torch.no_grad():\n",
    "        P_mc = utils.model.compute_UCM_P_count(\n",
    "            gp, likelihood, covariates, list(range(neurons)), MC=30, trials=1)  # predictive posterior\n",
    "    P_.append(P_mc.mean(0).cpu().numpy())  # take mean over MC samples\n",
    "P = np.concatenate(P_, axis=1)  # count probabilities of shape (neurons, timesteps, count)\n",
    "\n",
    "\n",
    "q = []\n",
    "Z = []\n",
    "trial = 0\n",
    "for n in range(neurons):\n",
    "    spike_binned = gpr.likelihood.all_spikes[trial, n, :].numpy()\n",
    "    q_ = utils.stats.counts_to_quantiles(P[n, ...], spike_binned, rng)\n",
    "    q.append(q_)\n",
    "\n",
    "q = np.array(q)  # quantiles of shape (neurons, timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# compare to model fit only to speed\u001b[39;00m\n\u001b[1;32m      2\u001b[0m a \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m}\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(a):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(b, v)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "# compare to model fit only to speed\n",
    "a = {'f': 1, 'd': 2}\n",
    "\n",
    "for b, v in zip(a):\n",
    "    print(b, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare to model fit only to hd-omega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare to model fit only to position"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39",
   "language": "python",
   "name": "python39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
