{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator # for minor ticks\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import patches\n",
    "from matplotlib.offsetbox import TextArea, VPacker, AnnotationBbox\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import scipy.stats as scstats\n",
    "import scipy.special as sps\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from neuroprob.utils import stats, tools, neural_utils, biophysical\n",
    "import neuroprob.models as mdl\n",
    "\n",
    "dev = tools.PyTorch()\n",
    "\n",
    "plt.style.use(['paper.mplstyle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inhomogenous Gamma process\n",
    "\n",
    "The inhomogeneous Gamma point process likelihood with rate $\\lambda(t)$ is \n",
    "\\begin{equation}\n",
    "    p(t_1, \\ldots, t_n) = \\frac{\\Gamma(\\alpha, \\Lambda(t_1)) \\Gamma(\\alpha, \\Lambda(t_n))}{\\Gamma(\\alpha)^n} \\cdot \\left[ \\prod_{i=1}^n \\lambda(t_i) \\right] \\cdot \\left[ \\prod_{i=2}^n(\\Lambda(t_i) - \\Lambda(t_{i-1}))^{\\alpha-1} \\right] \\cdot e^{-(\\Lambda(t_n) - \\Lambda(t_1))}\n",
    "\\end{equation}\n",
    "where $\\Lambda(t) = \\int_0^t \\lambda(\\tau) \\mathrm{d}\\tau$ and $\\Gamma(\\alpha, x)$ denotes the regularized upper incomplete Gamma function. It satisfies $\\Gamma(\\alpha, x) = 1 - G(\\alpha, x)$ with \n",
    "\\begin{equation}\n",
    "G(\\alpha n, \\lambda T) = \\frac{1}{\\Gamma(n\\alpha)} \\int_0^T \\lambda^{n\\alpha} \\tau^{n\\alpha - 1} e^{-\\lambda \\tau} \\cdot \\mathrm{d}\\tau\n",
    "\\end{equation}\n",
    "called the regularized lower incomplete Gamma function. The Gamma count process probability is given by \n",
    "\\begin{equation}\n",
    "    Pr(N_T = n) = G(\\alpha n, \\lambda T) - G(\\alpha (n+1), \\lambda T)\n",
    "\\end{equation}\n",
    "This distribution has $\\mathbb{E}[N_T] = \\sum_{k=1}^{\\infty} G(\\alpha k, \\lambda T)$.\n",
    "\n",
    "Let us consider the interspike intervals (ISIs), which are drawn from $Gamma(\\tau|\\alpha,\\lambda)$. The derivation for $Pr(N_T = n)$ can then be seen intuitively using the fact that $\\tau_1 + \\tau_2 \\sim Gamma(\\tau|\\alpha_1 + \\alpha_2,\\lambda)$. The first term is thus the probability that $n$ ISIs have a total sum below $T$, while the second term is the probability adding another ISI goes over the counting interval $T$. Note that except for the case $\\alpha = 1$ (exponential distribution), $\\mathbb{E}[\\tau]^{-1} \\neq \\mathbb{E}[N_T]$. Hence the rate parameter appearing in $\\mathbb{E}[\\tau] = \\frac{\\alpha}{\\lambda}$ cannot be interpreted as the 'rate' similar to the Poisson point process.\n",
    "\n",
    "The occupancy normalized histograms used to provide a non-parametric estimate of place fields are equivalent to calculating the point estimate of $\\mathbb{E}[N_T]$ for $T=1$, which by the above analysis shows this generally is a biased estimator of the underlying $\\mathbb{E}[\\tau]^{-1} = \\frac{\\lambda}{\\alpha}$ in that bin. However, numerically the values are close over a wide range of $\\alpha$. The differences are noticeable below $\\alpha \\approx 0.82$ when the bias is $>0.1$, with positive bias showing that naively using occupancy normalized histograms compensated by the shape overestimates the actual rate.\n",
    "\n",
    "Additionally, we assumed $\\mathbb{E}[N_{T_1}] + \\mathbb{E}[N_{T_2}] = \\mathbb{E}[N_{T_1+T_2}]$, which only holds approximately for Gamma count processes. We need $T \\gg \\frac{\\alpha}{\\lambda}$ in order to be able to ignore the effects of the renewal point process at the bin edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = 10.0\n",
    "shape = 0.5\n",
    "\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "gs1 = fig.add_gridspec(nrows=1, ncols=2, wspace=0.2, bottom=0.6, top=0.95)\n",
    "ax = fig.add_subplot(gs1[0, 0])\n",
    "ax2 = fig.add_subplot(gs1[0, 1])\n",
    "\n",
    "\n",
    "bins = np.arange(31)\n",
    "prbs = stats.gamma_count_prob(bins, rate, 1.0, 1.0)\n",
    "ax.plot(bins, prbs, color='r', label=r'Poisson')\n",
    "shape = 0.5\n",
    "prbs2 = stats.gamma_count_prob(bins, rate*shape, 1.0, shape)\n",
    "ax.bar(bins, prbs2, width=1, color='cyan', edgecolor='grey', linewidth=1)\n",
    "ax.set_xlim(-0.5, 30.5)\n",
    "ax.set_yticks([])\n",
    "ax.set_ylabel('probability')\n",
    "ax.legend()\n",
    "\n",
    "ax.text(-0.18, 1.05, 'A', transform=ax.transAxes, size=15)#, weight='bold') # string.ascii_uppercase[n]\n",
    "ax.text(0.25, 0.1, r'$\\alpha=\\frac{1}{2}$', transform=ax.transAxes, size=12)\n",
    "\n",
    "\n",
    "prbs = stats.gamma_count_prob(bins, rate, 1.0, 1.0)\n",
    "ax2.plot(bins, prbs, color='r')\n",
    "shape = 2.0\n",
    "prbs2 = stats.gamma_count_prob(bins, rate*shape, 1.0, shape)\n",
    "ax2.bar(bins, prbs2, width=1, color='cyan', edgecolor='grey', linewidth=1)\n",
    "ax2.set_xlim(-0.5, 30.5)\n",
    "ax2.set_yticks([])\n",
    "\n",
    "fig.text(-0.12, -0.28, 'spike count', transform=ax2.transAxes, fontsize=12, ha='center')\n",
    "ax2.text(0.25, 0.1, r'$\\alpha=2$', transform=ax2.transAxes, size=12)\n",
    "\n",
    "\n",
    "gs2 = fig.add_gridspec(nrows=1, ncols=3, wspace=0.4, bottom=0.05, top=0.45)\n",
    "ax = fig.add_subplot(gs2[0, 0])\n",
    "ax2 = fig.add_subplot(gs2[0, 1:])\n",
    "\n",
    "# checking correspondence of ISI average to count average\n",
    "eps = 5*1e-2\n",
    "alpha_arr = np.linspace(0.2, 3.0, 1000)\n",
    "beta = 100.0\n",
    "\n",
    "avg_count = []\n",
    "avg_invISI = []\n",
    "for alpha in alpha_arr:\n",
    "    h = 0\n",
    "    add = 1\n",
    "    n = 1\n",
    "    while add > 1e-4:\n",
    "        add = sps.gammainc(alpha*n, beta)\n",
    "        h += add\n",
    "        n += 1\n",
    "    avg_count.append(h)\n",
    "    avg_invISI.append(beta/alpha)\n",
    "        \n",
    "ax.text(-0.3, 1.0, 'B', transform=ax.transAxes, size=15)\n",
    "ax.plot(alpha_arr, np.array(avg_count), label=r'$\\mathbb{E}[N]$')\n",
    "ax.plot(alpha_arr, np.array(avg_invISI), 'r--', label=r'$\\mathbb{E}[\\tau]^{-1}$')\n",
    "ll = np.linspace(0, 6.9, 10)\n",
    "ax.plot(np.ones_like(ll), ll, color='#dddddd')\n",
    "\n",
    "ax.legend(frameon=False)\n",
    "#ax.set_xlim(0.2, 3.0)\n",
    "#ax.set_xticks([0.2, 1.0, 2.0])\n",
    "#ax.set_ylim(0.0, 6.9)\n",
    "ax.set_xlabel(r'$\\alpha$')\n",
    "ax.set_ylabel('count')\n",
    "\n",
    "\n",
    "\n",
    "# Spike trains\n",
    "ax2.text(-0.15, 1.0, 'C', transform=ax2.transAxes, size=15)\n",
    "\n",
    "trials = 5\n",
    "sim_samples = 1000\n",
    "sim_tbin = 0.001 # s\n",
    "rate = np.empty((trials, 1, sim_samples))\n",
    "\n",
    "rate.fill(5.0)\n",
    "dist_isi = mdl.point_process.ISI_gamma(0.25)\n",
    "s = mdl.point_process.gen_IRP(dist_isi, rate, sim_tbin)\n",
    "for t in range(trials):\n",
    "    s_ = s[t]\n",
    "    ax2.scatter(s_*sim_tbin, np.ones_like(s_)*t, marker='|', color='b', s=40, \n",
    "                label=r'$\\alpha=\\frac{1}{4}$')\n",
    "\n",
    "rate.fill(20.0)\n",
    "dist_isi = mdl.point_process.ISI_gamma(1)\n",
    "s = mdl.point_process.gen_IRP(dist_isi, rate, sim_tbin)\n",
    "for t in range(trials):\n",
    "    s_ = s[t]\n",
    "    ax2.scatter(s_*sim_tbin, np.ones_like(s_)*(t+trials+1), marker='|', s=40, color='k', \n",
    "                label=r'$\\alpha=1$')\n",
    "\n",
    "rate.fill(80.0)\n",
    "dist_isi = mdl.point_process.ISI_gamma(4)\n",
    "s = mdl.point_process.gen_IRP(dist_isi, rate, sim_tbin)\n",
    "for t in range(trials):\n",
    "    s_ = s[t]\n",
    "    ax2.scatter(s_*sim_tbin, np.ones_like(s_)*(t+2*trials+2), marker='|', s=40, color='g', \n",
    "                label=r'$\\alpha=4$')\n",
    "    \n",
    "ll = np.linspace(.0, 1., 10)\n",
    "ax2.plot(ll, np.ones_like(ll)*(trials), color='grey')\n",
    "ax2.plot(ll, np.ones_like(ll)*(2*trials+1.), color='grey')\n",
    "\n",
    "ax2.set_xlabel('time (s)')\n",
    "ax2.set_ylim(-1.5, trials*3+0.5 + 2)\n",
    "ax2.set_xlim(0.0, 1.0)\n",
    "\n",
    "ax2.set_yticks([2, 8, 14])\n",
    "ax2.set_yticklabels([r'$\\alpha=\\frac{1}{4}$  ', r'$\\alpha=1$  ', r'$\\alpha=4$  '])\n",
    "ax2.tick_params(axis='y', which='both', length=0)\n",
    "\n",
    "ax2.spines['left'].set_visible(False)\n",
    "\n",
    "\n",
    "#plt.savefig('output/gamma_process.svg')\n",
    "#plt.savefig('output/gamma_process.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn into count process\n",
    "sim_tbin = 0.001\n",
    "sim_samples = 1000\n",
    "trials = 10000\n",
    "gg = []\n",
    "\n",
    "rate = np.empty((trials, sim_samples))\n",
    "\n",
    "rate[:, :] = 5.0\n",
    "#rate[:, :sim_samples//2] = 100.0\n",
    "#rate[:, sim_samples//2:] = 0.0\n",
    "\n",
    "mode = 'gamma'\n",
    "if mode == 'gamma':\n",
    "    shape = 0.5\n",
    "    renew = mdl.point_process.ISI_gamma(shape)\n",
    "elif mode == 'invgauss':\n",
    "    mu = 1.\n",
    "    lambd = 1.\n",
    "    renew = mdl.point_process.ISI_invGauss(mu, lambd)\n",
    "elif mode == 'lognorm':\n",
    "    mu = 0.1\n",
    "    sigma = 1.\n",
    "    renew = mdl.point_process.ISI_logNormal(mu, sigma)\n",
    "    \n",
    "s = mdl.point_process.gen_IRP(renew, rate[:, None], sim_tbin)\n",
    "for k in range(len(s)):\n",
    "    gg.append(len(s[k]))\n",
    "    \n",
    "    \n",
    "ggg = []\n",
    "rate[:, :] = 5.0\n",
    "#rate[:, :sim_samples//2] = 100.0\n",
    "#rate[:, sim_samples//2:] = 0.0\n",
    "\n",
    "mode = 'gamma'\n",
    "if mode == 'gamma':\n",
    "    shape = 0.5\n",
    "    renew = mdl.point_process.ISI_gamma(shape)\n",
    "elif mode == 'invgauss':\n",
    "    mu = 1.\n",
    "    lambd = 1.\n",
    "    renew = mdl.point_process.ISI_invGauss(mu, lambd)\n",
    "elif mode == 'lognorm':\n",
    "    mu = 0.1\n",
    "    sigma = 1.\n",
    "    renew = mdl.point_process.ISI_logNormal(mu, sigma)\n",
    "    \n",
    "s = mdl.point_process.gen_IRP(renew, rate[:, None], sim_tbin)\n",
    "for k in range(len(s)):\n",
    "    ggg.append(len(s[k]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gggg = []\n",
    "for h in range(len(gg)):\n",
    "    gggg.append(gg[h]+ggg[h])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bins = np.arange(50)\n",
    "prbs = stats.gamma_count_prob(bins, 10.0, shape, sim_tbin*sim_samples)\n",
    "ax.plot(bins, prbs, 'r--', label=r'theory ($\\alpha$={})'.format(shape))\n",
    "ax.hist(gg, bins=np.arange(50)-0.5, density=True, label='simulation')\n",
    "ax.legend()\n",
    "ax.set_xlabel('Spike count')\n",
    "ax.set_ylabel('Probability')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bins = np.arange(100)\n",
    "prbs = stats.gamma_count_prob(bins, 5.0, shape, sim_tbin*sim_samples)\n",
    "ax.plot(bins, prbs, 'r--', label=r'theory ($\\alpha$={})'.format(shape))\n",
    "ax.hist(ggg, bins=np.arange(100)-0.5, density=True, label='simulation')\n",
    "ax.legend()\n",
    "ax.set_xlabel('Spike count')\n",
    "ax.set_ylabel('Probability')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bins = np.arange(100)\n",
    "prbs = stats.gamma_count_prob(bins, 15.0, shape, sim_tbin*sim_samples)\n",
    "ax.plot(bins, prbs, 'r--', label=r'theory ($\\alpha$={})'.format(shape))\n",
    "ax.hist(gggg, bins=np.arange(100)-0.5, density=True, label='simulation')\n",
    "ax.legend()\n",
    "ax.set_xlabel('Spike count')\n",
    "ax.set_ylabel('Probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
